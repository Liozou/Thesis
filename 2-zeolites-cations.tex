%!TeX root = main.tex
\documentclass[main.tex]{subfiles}

\begin{document}

\chapter{Cation placement in zeolites}\label{cationzeolites}
\vspace*{-1\baselineskip}

Among the different families of adsorbents, zeolites are among the most used in industry. Small gases tend to adsorb preferentially on cations when they are present, which makes the study of cationic zeolites particularly relevant to the understanding of industrial adsorption processes. This chapter presents the chemical nature of cationic zeolites and explain the challenges and methods used to obtain representative models of them for subsequent adsorption simulations. The central part of the chapter focuses on the newly developed ``shooting star'' methodology, which significantly reduces the amount of resource needed to compute the repartition of cations in zeolites.

\section{Cationic zeolites}

In this section, we detail the general structure of cationic zeolites and highlight the challenges associated with the simulation of such systems.

\subsection{Structure and properties}

Zeolites are a family of aluminosilicates, first discovered by Axel Fredrik Cronstedt in 1756. Similar to glass, their atomic structure is made of tetrahedra where the central atom, called a T-atom, is usually silicon, bridged together by oxygens. They are crystalline however, with typical unit cell lengths varying between \qty{10}{\angstrom} and \qty{100}{\angstrom}, and have nanopores.

The different kinds of zeolites are separated by topology: each known zeolite topology is given a capital three-letter code by the International Zeolite Association Structure Committee (IZA-SC). As explained in~\cref{topology_introduction}, the topology designates the information extracted from the network of chemical bonds: in the case of zeolites, this network can be simplified by taking one vertex per T-atom, and abstracting each oxygen bridge as a simple edge between the two corresponding T-atoms. This simple protocol makes it clear that the net of a zeolite is very close to the structure it represents --~in other words, simplifying the crystal into its net does not lose much information on the initial structure --~which explains why a classification by topology is the primary way to distinguish different zeolite structures. It is noteworthy that such a classification is vastly insufficient in the case of MOFs, where the chemistry of metal nodes and the nature of the ligands is thus used first; while for other kinds of materials such as glasses, it is downright impossible to establish because of the absence of cell periodicity.

While millions of hypothetical zeolite topologies have been identified by numerical methods [10.1039/C0CP02255A], only 256 have been experimentally observed\footnote{plus 9 intergrowth families, which are not strictly crystalline} as of 2024. This discrepancy may stem from the metastability of zeolites, whose porosity make them thermodynamically less favourable than glass [10.1021/acs.cgd.3c00893]. On the other hand, new experimental zeolite topologies have been discovered each year in the last twenty years, which indicate that accessing new structures is also limited by the current synthetic methods used. Moreover, new synthetic routes can allow new chemistry on existing topologies [10.1039/D2SC06010H, REF].

Indeed, each given topology may give rise to several zeolites that differ by their exact chemical composition. Isoelectronic metal substitution consists in the replacement of silicon by germanium or, in some cases, titanium, zinc or tin [REF]. A much more common kind of substitution consists in replacing some T-atoms by aluminium, or, more anecdotally, boron, gallium [REF]: each such substitution introduces one extra electron in the system, hence these zeolites contain cations to maintain electroneutrality. The nature of the cation itself leads to some more variability: sodium cations are usually the ones used during synthesis [REF], and can then be substituted by other cations [REF]. For simplicity, all zeolites discussed will be considered having only either Si or Al as T-atoms.

Ion exchange is actually the most prevalent industrial use case for cationic zeolites, especially as water softener for laundry agents [REF]. Their considerable internal surface and the accessibility of active sites such as the cations or the substituted metals make them also useful for catalysis [REF]. Other applications include nuclear waste storage, building material additives, water absorbents, soil treatment [REF], oxygen and contrast agent carrier for cancer treatment [10.1039/D3QI00169E] and others. Finally, they can be used as adsorbents for gas separation or storage, which is also of capital industrial interest.

Zeolite structures are mostly considered rigid structures in simulations, although some notable exceptions exist [10.1021/acs.chemmater.5b02103, 10.1126/science.abn7667], and most actually posess a flexibility window [10.1039/C003977B] which is exploited, especially during adsorption [10.1016/j.micromeso.2016.10.005]. In addition, T-atom substitution tends to modify only slightly the T-O bond length (Si-O: REF while Al-O: REF) and does not affect the O-T-O angles [REF]. As a consequence, the structure of a substituted zeolite can usually be well approximated by taking the reference structure of the topology (provided as a pure silicate by the IZA-SC) and replacing the relevant silicon atoms. However, not all placements of the substituents may correspond to existing zeolites

\subsection{Aluminium placement}

Cationic zeolites have some aluminiums as part of their structure, however their repartition among the T-atoms raises many questions.

\subsubsection{Rules}

The first rule, which is obeyed by almost all known zeolites, was discovered by L\"owenstein [REF]. It states that no two aluminiums may be neighbours, in the topological sense of being bridged by an oxygen. This hard rule limits the maximum number of aluminiums to half the number of T-atoms in general, and less for topologies that contain odd cycles: for instance, if there is a cycle of 5 T-atoms, only two among them can be Al.

The amount of aluminiums in a zeolite is usually discussed in terms of \SiAl ratio. L\"owenstein's rule thus limits the minimal \SiAl ratio to 1 in general, which corresponds to the maximum number of Al and thus of cations. Zeolites with high \SiAl ratios, usually called high-silica zeolites, contain few cations and tend to be hydrophobic [REF]; in general, they also tend to adsorb fewer molecules since cations are privileged adsorption sites.

While L\"owenstein's rule is widely accepted as an axiom, and is mainly sustained by the absence of experimental synthesis of any zeolite with \SiAl ratio lower than 1, it is not currently proven. This comes from the cost of the few spectroscopic methods that allow identifying the precise locations of Al atoms: \ce{^{27}Al} and \ce{^{29}Si} magic-angle spinning NMR can be used to provide some limited information, while [10.1039/B203966B, 10.1039/B301634J] used UV-Visible-NIR spectroscopy on \ce{Co^{2+}}-exchanged ZSM-5 with high \SiAl ratio to retrieve their Al distribution. But this method cannot be generalized to low-silica zeolites. DFT computation confirms the rule in general, but also show potential violations for some zeolite topologies such as HEU [10.1016/j.mtcomm.2021.102028].

The second rule, proposed by [REF Dempsey et al, 10.1021/j100722a020] on the basis of FAU zeolites with varying \SiAl ratios, states that when possible, the number of next-neighbours Al atoms should be minimized to decrease the number of unfavourable interactions between close aluminiums. This rule is actually known to be violated in many real zeolites, including dealuminated FAU. Speculatively, this may come from the fact that the [REF Dempsey et al] made their observations on zeolites whose synthesis lead them to reach their global energy minimum, while many other synthetic routes can create structures trapped in a local energy minimum with respect to their \SiAl ordering.

\subsubsection{Simulation methodologies}

Overall, the lack of experimental evidence attesting to the precise position of aluminiums in zeolites make the theoretical prediction of such placement delicate, since it lacks verifiable comparison points. In particular, a crucial question is whether \SiAl ordering is truly guided by thermodynamical consideration or not [10.1007/s11814-021-0796-2]. The latter case would appear for zeolites whose structure is in a metastable state, which is likely to be the case for many real zeolites as evidenced by [10.1039/B301634J] in one of the few experimental studies tackling that very issue.

Even if the aluminium placement can be obtained as that which minimizes the global energy of the structure, this does not necessarily mean that the placement itself is periodic, nor that it follows the same periodicity as the unit cell. Yet, as it is difficult to provide a concrete result on the localisation of aluminiums without making such hypotheses, the studies in the literature only focus on the study of the placement of aluminiums in a single unit cell, supposing that the rest is periodic.

In these conditions, the last remaining question is the simulation methodology to use to find the global energy minimum of the structure. The most basic method consists in generating all possible configurations, computing their energy, and choosing that which minimizes the energy. This approach has actually been widely followed to find the preferred location of aluminiums when there are only one or two aluminiums per unit cell, using Density Functional Theory (DFT) to compute the energy [10.1007/s11814-021-0796-2, REF]. The involved computational cost makes it impractical for lower \SiAl ratios however, which are of major interest for adsorption purposes.

[REF Marie Jeffroy]\label{mariejeffroy_al} proposed a more refined Monte-Carlo (MC) protocol for this problem, based on classical force fields for energy computation. Starting from a configuration with the target \SiAl ratio under L\"owenstein's rule, each MC step consists in exchanging the positions of a Si and an Al while maintaining L\"owenstein's rule, and accepting or refusing the step according to the Metropolis-Hastings criterion (explained in \cref{metropolis}). For low \SiAl ratios, this algorithm requires adding some ``restart'' option that entirely repopulates the aluminiums at random under L\"owenstein's rule, because that very rule can lead to blocked situation where no single \SiAl exchange is possible, as illustrated on \cref{fig:blocked_situation}.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/cations/blocked_situation.pdf}
	\caption{Schematic representation of aluminium placement in a zeolite fragment. Empty circles represent silicium, filled circles represent aluminium. Black edges represent -O- bridges. L\"owenstein's rule forbids two aluminiums from being neighbors.\\a) An exchange move between a silicium and an aluminium.\\b) The result of the exchange.\\c) A blocked configuration where no move is possible.\\d) A configuration with one more aluminium, which cannot be reached from c).}\label{fig:blocked_situation}
\end{figure}

[REF Findley et al., 10.1021/acs.jpcc.8b03475] proposed an innovative method to assess the validity of theoretically-obtained aluminium placements, by studying \ce{CO_2} adsorption isotherms. They found that different \SiAl orderings lead to different isotherms, which, conversely, means that obtaining a precise experimental isotherm can allow retrieving the degree of Al ordering. In accordance to other results of Marie Jeffroy [REF], they conclude that some topologies (REF) are more likely to have their aluminiums placed at random compared to others (REF).

Hence, given the uncertainty that any aluminium placements obtained by thermodynamical simulation actually reflects those observed in real zeolites, we choose to consider that the aluminium placement in our zeolites is taken at random. In practise, each zeolite with a given \SiAl ratio will be modelled as the average of six zeolites of that topology with the same \SiAl ratio, all following L\"owenstein's rule but having different Al repartition (taking symmetry into account as well). The results will be computed on each of these six models, and averaged to obtain the result for the zeolite.

To obtain the zeolite structures with random aluminium placements obeying L\"owenstein's rule and the target \SiAl ratio, we use the following algorithm:
\begin{itemize}
    \item The starting point is either the zeolite filled with Si if the required \SiAl ratio is above 3, else a zeolite filled with as many Al as possible using a greedy algorithm. That greedy technique consists in doing a graph traversal of the T-atoms, transforming each atom into an Al if it is not the neighbour of an Al, or making it a Si otherwise: if all cycles in the graph are even, this is guaranteed to provide an aluminium placement with the minimal \SiAl of 1.
    \item The main algorithm then alternates between adjusting the number of Al and changing their positions, for a few steps each, back and forth.
    \begin{itemize}
        \item The position update follows the principle of Marie Jeffroy's MC scheme but disregarding the energy change: one Si and one Al are exchanged at random if the resulting structure still follows L\"owenstein's rule.
        \item The number of Al atoms is modified if the current \SiAl ratio does not correspond to the target: if it is too high, an Al is converted into a Si, and otherwise a Si that has no Al neighbour is converted into an Al.
    \end{itemize}
    \item Since the situation can be blocked (see [FIGURE]), the algorithm sometimes restart from scratch, or sometimes does a partial restart by converting multiple Al atoms into Si.
    \item Configurations where the correct \SiAl ratio is reached are kept in a set. Each configuration is assigned a hash, which is simply a sequence of 0 if the T-atom is a Si or 1 otherwise, in a fixed order of the T-atom. To avoid considering symmetry-equivalent configurations as different, the signature of a configuration is computed as the lexicographically minimum of all the hashes corresponding to the application of a symmetry operation on the configuration. For each unique signature, a corresponding configuration is then retained, and the six models are taken at random among these configurations.
\end{itemize}

One last consideration is the choice of the supercell. It appears that, for a large number of zeolites topologies, the smallest unit cell cannot be filled with aluminiums so that it both obeys L\"owenstein's rule and reaches the minimal \SiAl ratio for that topology. In the case of LTA for instance, the smallest compatible cell is a $2\times2\times2$ supercell of the smallest unit cell. As a consequence, the greedy algorithm used before is actually attempted on several supercells, and the one leading to the smallest \SiAl ratio is retained.

The full list of minimum \SiAl ratio found for each zeolite topology (except interrupted ones) and the respective supercell is presented in \cref{table:zeosial}. The supercell is considered with respect to the idealized framework available for each topology on the IZA-SC database\footnote{accessible at \url{https://europe.iza-structure.org/IZA-SC/ftc_table.php}}. This table presents the lowest \SiAl ratio found, but apart for the cases where it is $1$, the values here are not proven to be minimal, since the algorithm relies on random attempts. Similarly, the supercell used could be not minimal.

It is worth mentioning that a previous screening study of adsorption in zeolite by [10.1021/acsami.0c20892] claimed to use the lowest possible \SiAl ratios to screen through zeolites, but failed to reach the ones presented here, systematically in the case where a supercell needed to be used. Another [10.1021/acs.jpcc.3c06115, 10.1021/acs.jpcc.4c00066] alluded to that issue in the case of LTA, yet failed to identify some other topologies (ATT, JBY, LEV, LTL, MRT, OFF) which could reach an \SiAl ratio of 1. The choice of the supercell during aluminium placement is thus an easily overlooked, yet critical, point to consider.


\begin{table}
\small
\makebox[\textwidth]{%
\hspace{6pt}\begin{minipage}[t]{0.24\linewidth}
	\vspace{0pt}
	\begin{tabular}{|@{\hspace{0pt}}c@{\hspace{0pt}}|@{\hspace{1pt}}c@{\hspace{1pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|}
		\hline
		\scriptsize \bf Topology&\scriptsize \bf Si/Al&\scriptsize \bf Supercell\\\hline
ABW&$1$&1$\times$1$\times$1\\\hline
ACO&$1$&1$\times$1$\times$1\\\hline
AEI&$1$&1$\times$1$\times$1\\\hline
AEL&$1$&1$\times$1$\times$1\\\hline
AEN&$1$&1$\times$1$\times$1\\\hline
AET&$1$&1$\times$1$\times$1\\\hline
AFG&$1$&1$\times$1$\times$1\\\hline
AFI&$1$&1$\times$1$\times$1\\\hline
AFN&$1$&1$\times$1$\times$1\\\hline
AFO&$1$&1$\times$1$\times$1\\\hline
AFR&$1$&2$\times$2$\times$4\\\hline
AFS&$1$&1$\times$1$\times$1\\\hline
AFT&$1$&1$\times$1$\times$1\\\hline
AFV&$1$&3$\times$3$\times$2\\\hline
AFX&$1$&1$\times$1$\times$1\\\hline
AFY&$1$&1$\times$1$\times$1\\\hline
AHT&$1$&1$\times$1$\times$1\\\hline
ANA&$1$&1$\times$1$\times$1\\\hline
ANO&$1$&1$\times$1$\times$1\\\hline
APC&$1$&1$\times$1$\times$1\\\hline
APD&$1$&1$\times$1$\times$1\\\hline
AST&$1$&1$\times$1$\times$1\\\hline
ASV&$1$&1$\times$1$\times$1\\\hline
ATN&$1$&1$\times$1$\times$1\\\hline
ATO&$1$&1$\times$1$\times$1\\\hline
ATS&$1$&1$\times$1$\times$1\\\hline
ATT&$1$&3$\times$4$\times$3\\\hline
ATV&$1$&1$\times$1$\times$1\\\hline
AVE&$1$&1$\times$1$\times$1\\\hline
AVL&$1$&3$\times$3$\times$2\\\hline
AWO&$1$&1$\times$1$\times$1\\\hline
AWW&$1$&2$\times$2$\times$4\\\hline
BCT&$1$&1$\times$1$\times$1\\\hline
BEC&$1.29$&2$\times$2$\times$2\\\hline
BIK&$1.4$&4$\times$2$\times$5\\\hline
BOF&$1.4$&2$\times$1$\times$1\\\hline
BOG&$1.4$&1$\times$1$\times$1\\\hline
BOZ&$1.88$&1$\times$1$\times$1\\\hline
BPH&$1$&1$\times$1$\times$1\\\hline
BRE&$1.29$&4$\times$2$\times$4\\\hline
BSV&$1$&1$\times$1$\times$1\\\hline
CAN&$1$&1$\times$1$\times$1\\\hline
CAS&$1.4$&1$\times$1$\times$1\\\hline
CDO&$1.62$&4$\times$2$\times$2\\\hline
CFI&$1.46$&2$\times$5$\times$1\\\hline
CGF&$1$&2$\times$2$\times$4\\\hline
CGS&$1$&1$\times$1$\times$1\\
\end{tabular}
\end{minipage}\hspace{4pt}
\begin{minipage}[t]{0.24\linewidth}
	\vspace{0pt}
	\begin{tabular}{|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|}
CHA&$1$&1$\times$1$\times$1\\\hline
CON&$1.33$&1$\times$1$\times$1\\\hline
CSV&$1.22$&1$\times$2$\times$1\\\hline
CZP&$1$&1$\times$1$\times$1\\\hline
DAC&$1.57$&1$\times$3$\times$2\\\hline
DDR&$1.73$&1$\times$2$\times$1\\\hline
DFO&$1$&2$\times$2$\times$2\\\hline
DFT&$1$&4$\times$4$\times$3\\\hline
DOH&$1.62$&1$\times$2$\times$1\\\hline
DON&$1.29$&1$\times$1$\times$1\\\hline
EAB&$1$&1$\times$1$\times$1\\\hline
EDI&$1$&4$\times$4$\times$4\\\hline
EEI&$1.44$&1$\times$1$\times$1\\\hline
EMT&$1$&1$\times$1$\times$1\\\hline
EON&$1.4$&2$\times$1$\times$1\\\hline
EOS&$1.18$&1$\times$2$\times$2\\\hline
EPI&$1.74$&4$\times$2$\times$3\\\hline
ERI&$1$&1$\times$1$\times$1\\\hline
ESV&$1.4$&1$\times$1$\times$1\\\hline
ETL&$1.48$&2$\times$1$\times$1\\\hline
ETR&$1$&1$\times$1$\times$1\\\hline
ETV&$1.33$&1$\times$1$\times$1\\\hline
EUO&$1.49$&1$\times$1$\times$1\\\hline
EWF&$1.49$&2$\times$1$\times$1\\\hline
EWO&$1.4$&2$\times$2$\times$5\\\hline
EWS&$1.53$&1$\times$1$\times$1\\\hline
EZT&$1$&1$\times$1$\times$1\\\hline
FAR&$1$&1$\times$1$\times$1\\\hline
FAU&$1$&1$\times$1$\times$1\\\hline
FER&$1.57$&1$\times$1$\times$3\\\hline
FRA&$1$&1$\times$1$\times$1\\\hline
GIS&$1$&1$\times$1$\times$1\\\hline
GIU&$1$&1$\times$1$\times$1\\\hline
GME&$1$&1$\times$1$\times$1\\\hline
GON&$1.29$&1$\times$1$\times$1\\\hline
GOO&$1$&1$\times$1$\times$1\\\hline
HEU&$1.25$&1$\times$1$\times$2\\\hline
IFO&$1$&1$\times$1$\times$1\\\hline
IFR&$1.29$&1$\times$1$\times$2\\\hline
IFW&$1.29$&1$\times$1$\times$1\\\hline
IFY&$1$&1$\times$1$\times$2\\\hline
IHW&$1.55$&1$\times$1$\times$1\\\hline
IMF&$1.55$&1$\times$1$\times$1\\\hline
IRN&$1.19$&1$\times$1$\times$1\\\hline
IRR&$1.6$&2$\times$2$\times$2\\\hline
ISV&$1.31$&2$\times$2$\times$1\\\hline
ITE&$1.56$&1$\times$2$\times$1\\\hline
ITG&$1.33$&1$\times$1$\times$2\\
\end{tabular}
\end{minipage}\hspace{0pt}
\begin{minipage}[t]{0.24\linewidth}
\vspace{0pt}
\begin{tabular}{|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|}
ITH&$1.33$&1$\times$2$\times$1\\\hline
ITR&$1.33$&1$\times$1$\times$1\\\hline
ITT&$1.56$&2$\times$2$\times$3\\\hline
ITW&$1.4$&1$\times$1$\times$1\\\hline
IWR&$1.33$&2$\times$2$\times$2\\\hline
IWS&$1.27$&1$\times$1$\times$2\\\hline
IWV&$1.62$&1$\times$1$\times$2\\\hline
IWW&$1.33$&1$\times$1$\times$1\\\hline
JBW&$1$&5$\times$4$\times$3\\\hline
JNT&$1$&1$\times$1$\times$1\\\hline
JOZ&$1.5$&2$\times$1$\times$1\\\hline
JRY&$1$&1$\times$1$\times$1\\\hline
JSN&$1$&3$\times$4$\times$2\\\hline
JSR&$1.67$&1$\times$1$\times$1\\\hline
JST&$2$&1$\times$1$\times$1\\\hline
JSW&$1$&1$\times$1$\times$1\\\hline
JSY&$1$&1$\times$1$\times$1\\\hline
JZO&$1.37$&1$\times$1$\times$1\\\hline
JZT&$1.35$&1$\times$1$\times$1\\\hline
KFI&$1$&1$\times$1$\times$1\\\hline
LAU&$1$&2$\times$2$\times$4\\\hline
LEV&$1$&3$\times$3$\times$2\\\hline
LIO&$1$&1$\times$1$\times$1\\\hline
LOS&$1$&1$\times$1$\times$1\\\hline
LOV&$1.25$&2$\times$2$\times$1\\\hline
LTA&$1$&2$\times$2$\times$2\\\hline
LTF&$1.27$&1$\times$1$\times$4\\\hline
LTJ&$1$&1$\times$1$\times$1\\\hline
LTL&$1$&2$\times$2$\times$4\\\hline
LTN&$1$&1$\times$1$\times$1\\\hline
MAR&$1$&1$\times$1$\times$1\\\hline
MAZ&$1.4$&1$\times$1$\times$2\\\hline
MEI&$1.43$&1$\times$1$\times$1\\\hline
MEL&$1.67$&1$\times$1$\times$1\\\hline
MEP&$1.71$&1$\times$1$\times$1\\\hline
MER&$1$&1$\times$1$\times$1\\\hline
MFI&$1.67$&1$\times$1$\times$1\\\hline
MFS&$1.45$&3$\times$1$\times$1\\\hline
MON&$1.67$&2$\times$2$\times$1\\\hline
MOR&$1.67$&1$\times$1$\times$2\\\hline
MOZ&$1$&1$\times$1$\times$4\\\hline
MRT&$1$&2$\times$4$\times$2\\\hline
MSE&$1.55$&1$\times$1$\times$1\\\hline
MSO&$1$&2$\times$2$\times$2\\\hline
MTF&$1.44$&1$\times$1$\times$2\\\hline
MTN&$1.72$&1$\times$1$\times$1\\\hline
MTT&$1.4$&1$\times$1$\times$1\\\hline
MTW&$1.33$&1$\times$5$\times$3\\
\end{tabular}
\end{minipage}\hspace{2pt}
\begin{minipage}[t]{0.24\linewidth}
\vspace{0pt}
\begin{tabular}{|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{5pt}}|}
MVY&$1$&1$\times$1$\times$1\\\hline
MWF&$1$&1$\times$1$\times$1\\\hline
MWW&$1.53$&2$\times$2$\times$1\\\hline
NAB&$1.5$&2$\times$2$\times$1\\\hline
NAT&$1.22$&2$\times$2$\times$4\\\hline
NES&$1.52$&1$\times$1$\times$1\\\hline
NON&$1.44$&1$\times$1$\times$1\\\hline
NPO&$2$&4$\times$4$\times$5\\\hline
NPT&$2$&2$\times$2$\times$2\\\hline
NSI&$1.4$&2$\times$5$\times$3\\\hline
OBW&$1.92$&1$\times$1$\times$1\\\hline
OFF&$1$&3$\times$3$\times$4\\\hline
OKO&$1.62$&1$\times$1$\times$1\\\hline
OSI&$1$&1$\times$1$\times$1\\\hline
OSO&$2$&1$\times$1$\times$1\\\hline
OWE&$1$&2$\times$4$\times$3\\\hline
PAU&$1$&1$\times$1$\times$1\\\hline
PCR&$1.5$&1$\times$1$\times$1\\\hline
PHI&$1$&1$\times$1$\times$1\\\hline
PON&$1$&1$\times$1$\times$1\\\hline
POR&$1$&1$\times$1$\times$1\\\hline
POS&$1.29$&1$\times$1$\times$1\\\hline
PSI&$1$&1$\times$1$\times$1\\\hline
PTF&$1.5$&1$\times$1$\times$1\\\hline
PTO&$1.4$&1$\times$1$\times$1\\\hline
PTT&$1$&1$\times$1$\times$1\\\hline
PTY&$1.5$&1$\times$1$\times$1\\\hline
PUN&$1.25$&1$\times$1$\times$1\\\hline
PWN&$1$&1$\times$1$\times$1\\\hline
PWO&$1.5$&1$\times$1$\times$1\\\hline
PWW&$1.5$&1$\times$1$\times$1\\\hline
RFE&$1.4$&1$\times$1$\times$1\\\hline
RHO&$1$&1$\times$1$\times$1\\\hline
RRO&$1.25$&2$\times$1$\times$1\\\hline
RSN&$1.59$&4$\times$1$\times$4\\\hline
RTE&$1.4$&1$\times$1$\times$2\\\hline
RTH&$1.53$&2$\times$1$\times$3\\\hline
RUT&$1.57$&2$\times$2$\times$3\\\hline
RWR&$1.6$&4$\times$4$\times$1\\\hline
RWY&$3$&1$\times$1$\times$1\\\hline
SAF&$1$&1$\times$1$\times$1\\\hline
SAO&$1$&1$\times$1$\times$1\\\hline
SAS&$1$&1$\times$1$\times$1\\\hline
SAT&$1$&1$\times$1$\times$1\\\hline
SAV&$1$&1$\times$1$\times$1\\\hline
SBE&$1$&1$\times$1$\times$1\\\hline
SBN&$1.5$&1$\times$2$\times$1\\\hline
SBS&$1$&1$\times$1$\times$1\\
\end{tabular}
\end{minipage}\hspace{7pt}
\begin{minipage}[t]{0.24\linewidth}
\vspace{0pt}
\begin{tabular}{|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{2pt}}|@{\hspace{2pt}}c@{\hspace{5pt}}|}
SBT&$1$&1$\times$1$\times$1\\\hline
SEW&$1.36$&1$\times$2$\times$1\\\hline
SFE&$1.33$&1$\times$1$\times$1\\\hline
SFF&$1.46$&2$\times$1$\times$2\\\hline
SFG&$1.47$&1$\times$2$\times$2\\\hline
SFH&$1.29$&5$\times$1$\times$2\\\hline
SFN&$1.29$&1$\times$5$\times$2\\\hline
SFO&$1$&2$\times$2$\times$4\\\hline
SFS&$1.67$&1$\times$1$\times$1\\\hline
SFW&$1$&1$\times$1$\times$1\\\hline
SGT&$1.49$&2$\times$2$\times$1\\\hline
SIV&$1$&1$\times$1$\times$1\\\hline
SOD&$1$&1$\times$1$\times$1\\\hline
SOF&$1.5$&1$\times$1$\times$1\\\hline
SOR&$1.18$&1$\times$1$\times$2\\\hline
SOS&$1.4$&2$\times$4$\times$3\\\hline
SOV&$1.29$&1$\times$1$\times$1\\\hline
SSF&$1.25$&2$\times$2$\times$2\\\hline
SSY&$1.33$&1$\times$1$\times$1\\\hline
STF&$1.46$&1$\times$1$\times$2\\\hline
STI&$1.25$&1$\times$1$\times$1\\\hline
STT&$1.46$&1$\times$1$\times$1\\\hline
STW&$1.5$&1$\times$1$\times$1\\\hline
SVV&$1.33$&1$\times$1$\times$1\\\hline
SWY&$1$&1$\times$1$\times$1\\\hline
SZR&$1.25$&1$\times$1$\times$2\\\hline
TER&$1.35$&1$\times$1$\times$1\\\hline
THO&$1$&2$\times$4$\times$4\\\hline
TOL&$1$&1$\times$1$\times$1\\\hline
TON&$1.4$&2$\times$2$\times$5\\\hline
TSC&$1$&1$\times$1$\times$1\\\hline
TUN&$1.53$&1$\times$1$\times$1\\\hline
UEI&$1$&1$\times$1$\times$1\\\hline
UFI&$1.29$&2$\times$2$\times$1\\\hline
UOS&$1.18$&2$\times$4$\times$3\\\hline
UOV&$1.38$&1$\times$1$\times$1\\\hline
UOZ&$1$&1$\times$1$\times$1\\\hline
USI&$1$&1$\times$1$\times$1\\\hline
UTL&$1.62$&1$\times$2$\times$2\\\hline
UWY&$1.37$&1$\times$2$\times$3\\\hline
VET&$1.43$&1$\times$1$\times$1\\\hline
VFI&$1$&1$\times$1$\times$1\\\hline
VNI&$1.73$&3$\times$3$\times$1\\\hline
VSV&$1.78$&4$\times$4$\times$1\\\hline
WEI&$1.5$&1$\times$1$\times$1\\\hline
YFI&$1.4$&1$\times$1$\times$1\\\hline
YUG&$1.56$&3$\times$2$\times$4\\\hline
ZON&$1$&4$\times$2$\times$2\\\hline
	\end{tabular}
\end{minipage}\hspace{-2em}
}
\normalsize
	\caption{Minimal Si/Al and corresponding supercell obtained for all 239 non-interrupted topologies}
	\label{table:zeosial}
%\end{minipage}
\end{table}

\subsection{Cations}

The electroneutrality of the framework requires that each negative introduced by an Al substitution be compensated by the introduction of a cation in the framework. In many cases, \ce{Na^+} or \ce{H^+} are used during synthesis; they are sometimes replaced by other cations in later steps.

These cations have a primordial role for adsorption processes, because they constitute privileged adsorption sites for many small gases. The precise mechanism by which they contribute to the overall adsorption capacity of a material depends on their nature, their location, and the nature of the guest molecule however. Moreover, in addition to simple one-to-one adsorption cases of a small molecule on a cation, X-ray spectroscopy evidences the presence of adsorption complexes involving several cations and guest molecules at the same time [10.1039/C2CP23237E]. Finally, the very nature of the cations present in the structure can be quite diverse, ranging from monovalent alkali to polyvalent metal ions, and even molecular ions such as many of the organic structure directing agents (OSDAs) used during zeolite synthesis.

In order to perform numerical simulation of the adsorption process, it is thus necessary to have a model of the zeolite that places its cations in the correct positions. Fortunately, and opposite to the previous case of aluminiums, X-ray diffraction is a convenient technique which can be used to obtain the crystallographic sites in which the cations are located, as well as the respective occupancy of each such site.


\section{Prediction of cation placement}

While experimental cation maps are available on some zeolite structures, two seminal problems remain. First, when screening through a large amount of zeolite topologies and \SiAl ratio, only a small fraction of structures have their experimental cation map available. Second, even with the crystallographic sites, not all cation repartitions that obey the given occupancies have the same energy. For example, the site I and I' of FAU being very close to one another, the occupation of a site I prevents either of the neighbouring sites I' from being occupied at the same time. Deciding on the exact location of cations in a zeolite model is thus no trivial matter.

\subsection{Current methodologies}

To obtain equilibrium data, such as average positions, on molecular systems, there are two general simulation frameworks which can be used: molecular dynamics and Monte-Carlo (MC) simulation. We only used MC and its variations, because they are the only strategy available to study a variable number of molecules, which is necessary for the simulation of adsorption as we will explain in more details in \cref{gcmc}. The possible use of molecular dynamics and its variants will be discussed later in \cref{metadynamics}.

\subsubsection{Canonical Monte-Carlo}
% mention ergodicity

The Monte-Carlo (MC) method designates a large variety of algorithms which all converge towards their result by performing multiple random samplings. A wide subset of these form the Markov Chain Monte-Carlo (MCMC) schemes, which are a class of algorithms that aim at sampling a target probability distribution. In the context of statistical physics, such methods provide practical ways of obtaining macroscopic observable values from the simulation of the microscopic behaviour of particles. Indeed, an observable $\mathcal O$ can be computed as the ensemble average of its microscopic counterpart $\left<o\right>$, which can be computed as an integral over the configuration space. For example, in the canonical ensemble where the number of particles, the external temperature and the volume of the system is fixed, \[\mathcal O = \left<o\right> = \frac1Z\int\text d{\boldsymbol p} o\left({\boldsymbol p}\right)\exp\left(-\beta U\left({\boldsymbol p}\right)\right)\] where $ U\left({\boldsymbol p}\right)$ is the energy of configuration $\boldsymbol p$ and $Z$ is the partition function. In other words, $\mathcal O$ can be computed as an integral of values of $o$ on a probability distribution of $\boldsymbol p$ given by $p\mapsto \frac1Z\exp\left(-\beta U\left({\boldsymbol p}\right)\right)$.

The direct evaluation of this probability distribution is impossible in general, because of the partition function $Z$ whose value cannot be computed. Instead, the MCMC method gives a way to directly evaluate the observable $\mathcal O$ by providing a sequence of configurations $\boldsymbol p$ that follows the same probability distribution as the target. The integral can then be computed as simply the average value of $o$ on this specific set of configurations $\boldsymbol p$.

\label{metropolis}

The Metropolis-Hastings algorithm is the most common MCMC scheme used to provide such a sequence of configurations. It consists in starting from an initial state, \textit{i.e.} an initial position for all the mobile particles of the system, and making it evolve through a sequence of steps. At each step, a trial move, \textit{i.e.}, a modification of the state, is attempted and may, or may not, be accepted with a certain probability. In the case of a simulation in the canonical ensemble, the difference of energy $\Delta E$ between after and before the move gives the probability $\min\left(1, \exp\left(-\beta \Delta E\right)\right)$ that the move be accepted. Intuitively, this means that any move that decreases the energy of the system is accepted, while the others are accepted with a probability that decreases as the energy difference increases, sharply at low temperature and more slowly at high temperature. In the limit of infinite temperature, all the moves are accepted; at zero temperature, only the moves that decrease the energy are. The details on how to compute energy are deferred to \cref{energy_computation}.

To avoid drift, the algorithm obeys detailed balance which, conceptually, represents the microreversibility of the simulated physical processes. In practise, this means that, for each MC move that brings the system from configuration ${\boldsymbol p}_\mathcal{A}$ to ${\boldsymbol p}_\mathcal{B}$, there must exist a ``converse'' MC moves that can bring the system from $\mathcal{B}$ to $\mathcal{A}$ such that $\pi_\mathcal{A} P_{\mathcal{A}\to \mathcal{B}} = \pi_\mathcal{B} P_{\mathcal{B}\to \mathcal{A}}$ where $\pi_\mathcal{X}$ is the stationary probability of state ${\boldsymbol p}_\mathcal{X}$ and $P_{\mathcal{X}\to \mathcal{Y}}$ is the probability of the move from ${\boldsymbol p}_\mathcal{X}$ to ${\boldsymbol p}_\mathcal{Y}$. In the canonical ensemble, $\pi_\mathcal{X}$ is equal to to $\frac1Z\exp\left(-\beta U\left({\boldsymbol p}_\mathcal{X}\right)\right)$, while the probability of transition is $\min\left(1, \exp\left(-\beta \Delta E\right)\right)$. Hence, detailed balance simply translates to the algorithmic condition that the probability of choosing the trial move $\mathcal{A}\to \mathcal{B}$ must be equal to that of choosing the trial move $\mathcal{B}\to \mathcal{A}$, irrespective of the probability of accepting these moves.

The MC moves which are used for simulations in the canonical ensemble are usually the following:
\begin{itemize}
    \item translation: displace each atom of the particle by the same vector, taken uniformly at random in a sphere.
    \item rotation: rotate the particle around one of its atoms (called the ``bead'') along three uniformly random Euler angles, possibly constrained to some values only, most often all values under a maximum angle.
    \item reinsertion: remove and reintroduce the particle uniformly at random in the system.
\end{itemize}

Overall, the algorithm thus consists in a sequence of steps, each of which is an attempt to displace a cation either locally (translation) or not (reinsertion) and is accepted or not depending on the difference of energy the move generates. Configurations corresponding to neighbour steps are thus either identical if the move was refused, or only separate by one atom move, so they are strongly correlated. To reduce computational cost, the computation of the microscopic state function $o$ is thus only realized once every cycle, each cycle corresponding to a number of steps. We fix the number of steps per cycle to 100.

To satisfy detailed balance, the sphere in which the translation vector is taken must have a fixed radius, the bead must be fixed and the angle constraints must be symmetric. However, the best maximum translation length $d_{\max}$ and maximum angle $\theta_{\max}$ are those that yield a MC move acceptance rate of $1/2$. Since these optimal values depend on the precise simulation, it is customary to actually make these two constraints evolve along the simulation until reaching an acceptance rate of $1/2$. To do so, at the end of each cycle, they are updated with the following formulas:
\[\begin{split}
	d_{\max} &\gets \text{clamp}\paren{
		d_{\max}\times\paren{1+\paren{T_\text{ratio} - 1/2}\times\sqrt{\frac{10}{99+i}}},\ \qty{0.1}{\angstrom},\ \qty{3}{\angstrom}
	}\\
	\theta_{\max} &\gets \frac{i-1}i\times\theta_{\max} + \frac{R_\text{ratio}}{i}\times\qty{120}{\degree}
\end{split}\]
where $i$ is the number of the current cycle (starting at 1), $T_\text{ratio}$ (respectively $R_\text{ratio}$) is the ratio of accepted over attempted translations (respectively rotations) in the entire simulation, and clamp$(x, m, M)$ is $x$ if $m\le x \le M$, otherwise $m$ if $x\le m$, otherwise $M$ (if $x\ge M)$. Having $d_{\max}$ and $\theta_{\max}$ change across the simulation breaks detailed balance, which is theoretically forbidden; yet it does not actually pose a problem in because the formulas used ensure that the two values evolve smoothly towards the optimum, and become almost constants for long enough simulations.

At the beginning of each step, an MC move is chosen at random. In our simulations, all three moves (translation, rotation and reinsertion) are chosen equiprobably. For the particular case of the movement of mono-atomic species, such as most cations in zeolites, the rotation MC move is useless and thus not used, while the reinsertion move collapses to a simple translation with infinite $d_{\max}$, both moves being chosen equiprobably.

The Metropolis-Hastings algorithm thus provides a way to walk through the configuration space. By privileging moves that decrease energy, the system spends more steps in low energy regions; by yet allowing opposite moves sometimes, the scheme ensures that all the configuration space is eventually visited. Hence, the algorithm guarantees ergodicity: in an infinitely long simulation, the fraction of steps spent in a part of the configuration space is proportional to its volume. Finding the space with the lowest energy, and thus the largest probability and volume, should then simply be a matter of running the simulation long enough for the state to fall in the deepest energy pit.


\subsubsection{Simulated annealing}

Unfortunately, simply doing canonical MC at room temperature does not provide the cations with enough energy to overcome the barriers inherent to the structure of the zeolitic framework in any reasonable time. For example, a cation trapped in the site I of FAU will never manage escape into a site III in a room-temperature simulation of reasonable length without a reinsertion move: this simply comes from the high activation barrier it needs to overcome while physically moving out of the sodalite cage. Reinsertion moves are thus useful to allow large configuration movements to occur without having to pass through physical energy barriers.

However, a reinsertion can only move one particle at a time, which is sometimes not enough. For instance, the population of two sites I' from an initial configuration where only the central site I is occupied, requires that both the central cation move to the edge of the cage and that an external cation be set in the opposite window. Since both movements require passing through an activation barrier, the probability of it happening naturally is low, and thus requires particularly long simulation times to be observed.

To circumvent this issue, the temperature of the simulation can be raised: this mechanically makes all MC steps more likely to be accepted, so higher-energy regions become more reachable. At the same time, a simulation at a hot temperature is much less likely to explore the details of the energy landscape enough to fall into the energy minima of interest, since the accessible configuration space became so much larger. A compromise thus consists in performing simulated annealing, which is simply a simulation in which the temperature varies between cold and hot, alternating between increasing and decreasing phases, possibly interspersed with plateaus.

% TODO: comment, illustrate.

\subsubsection{Parallel tempering}

Simulated annealing explores the configuration space by alternating between cold phases, where the exploration is detailed but localized, and hot phases, where the exploration is fast but superficial. Parallel tempering, also called ``replica exchange'' proposes doing both phases at the same time.

In more detail, a parallel tempering simulation consists in running several MC simulations, the ``replicas'', in parallel, each at a different temperature. The temperatures are taken between room temperature and a hot temperature. An extra MC step is introduced, called the ``exchange'' step, which consists in exchanging the configurations of two replicas with neighbour temperatures. As with any MC step, the Metropolis-Hastings algorithm ensures that the exchange is accepted only if the difference of energy resulting from this exchange is not too high: as a consequence, for the exchange step to be accepted regularly, the temperatures must be taken so that the typical energies of the system between neighbour temperatures overlap, as shown on [FIGURE].

In this strategy, the coldest simulation is constantly exploring a local free energy minimum, while the hottest simulation easily accepts MC moves and thus walks through the entire configuration space. By exchanging configurations, new configurations regularly trickle down from the hot simulations to the colder ones, while the general Metropolis-Hastings strategy ensures convergence towards a global minimum. It is also more efficient than simulated annealing since the exploration of the configuration space is not constrained by the small duration of the hot phase. Parallel tempering is therefore the method of choice used to obtain convergence when facing difficult energy landscapes such as the one encountered for cation placement.

Naturally, its main downside is its computational cost, proportional to the number of simulations and thus effectively related to the difference between the highest and the lowest temperatures. The choice of intermediate temperatures must be guided by an initial discovery of the typical energies encountered by system at each temperature, which requires a few dedicated simulations prior to the parallel tempering. Finding the optimal number of simulations requires striking a balance with the proportion of accepted MC exchange steps, whose impact on the overall simulation convergence can be difficult to measure. Additionally, simulations with neighbour temperatures must regularly synchronize to attempt an exchange, which strongly limits the amount of parallelization usable in the implementation of parallel tempering.

\subsubsection{Combined aluminium and cation placement} % method of Marie Jeffroy

Specifically in the case cationic zeolites, [Marie Jeffroy REF] proposes a simulation method to obtain both the placement of cations in the structure and the location of aluminium atoms across the T-sites. This consists in running an MC simulation where the cations are allowed all previously mentioned MC steps, while the aluminiums are only allowed exchanging positions with siliciums, or a restart step that randomly positions aluminiums and siliciums, both while obeying L\"owenstein's rule as explained in \cref{mariejeffory_al}.

The statistical ensemble simulated in this setting includes both aluminium and cations, which means that the distribution sampled through such a simulation method represents the equilibrium for both species. From a chemical point of view, this situation is representative of a framework whose synthesis was done with that very cation, and was thermodynamically-driven. While this does correspond to reality in some cases, there is also evidence that the synthesis is kinetically-driven in many other occurences: for such situation, obtaining the aluminium positions from statistical equilibrium is not representative of the actual framework. And in yet other situations, the cation is exchanged post-synthesis, which decorrelates the aluminium placement in the framework from the cation used for adsorption purposes.

Nonetheless, even in those cases, there is no less value in the aluminium placement obtained from such a hybrid strategy than from random sampling of the T-atoms. In fact, by virtue of the added dimensions of the free energy landscape, a kinetically trapped cation may move more freely following the rearrangement of the aluminiums in the structure, which can make the entire simulation converge more efficiently. If not for the hope of obtaining more relevant aluminium placements, this combined strategy remains valuable for its diminished computationally cost compared to parallel tempering.

Unfortunately, the fact that the framework is not strictly constant as before prevents the use of precomputed energy grid, later discussed in \cref{energygrid}. This was not a problem in the context of [Marie Jeffroy]'s study because the force field they used was such that a silicium-aluminium swap would not change the van der Waals interactions, but this is not the case of most force fields, including the one we use in our study [BoulfelfelSholl2021]. Being unable to precompute the short-term energy contribution of the framework would thus make the simulations significantly slower, tipping the balance against the use of this method.

\subsection{Shooting star methodology}

Previously exposed methods such as canonical MC, simulated annealing or parallel tempering focus on making the system (or at least, one of its replicas) reach equilibrium after a certain number of initial steps, so that the rest of the simulation occurs at equilibrium. This is crucial for the problem of sampling the equilibrium distribution of states in general. For the case of cation placement in zeolites however, the observed crystallographic positioning of the cations indicates that this distribution is sharply peaked: only a discrete number of sites can be occupied, and the question is to find their positions and occupancy. As a consequence, we can use another, simpler, strategy, which is less efficient for the actual sampling of the distribution, but can uncover relevant local minima faster.

\subsubsection{Principle}

This new methodology takes the same simulation elements as the ones previously detailed, but arranges them in a different fashion. We call it ``shooting star'' because it can be decomposed into one hot simulation, like the bright head of the meteor, and a series of cold simulations that stem from it, like the cooling incandescent debris left in its wake.

The first element is the exploration of the phase space. In order to fully explore it, a naive approach consists in doing steps, each of which randomly reinserts a particle in the system. Without the possibility for step rejection, this leads to sampling extremely unlikely states almost all the time however. We propose to perform global exploration by simply running a canonical MC simulation at a very high temperature, for instance \qty{2000}{K}. Such an approach makes most kinetic obstacles irrelevant, but still prevents absurd configurations like when two atoms collide. This MC simulation is simply called the hot simulation.

The second element is the local minima exploration, which is grafted onto the previous one: every $\Delta_{\text{spawn}}$ cycles of the hot simulation, a snapshot of its current configuration is taken and used as the starting point for a cold simulation, \textit{i.e.} another canonical MC simulation that runs at room temperature. $\Delta_{\text{spawn}}$ is chosen so that two consecutive starting points should be uncorrelated. The higher the temperature of the hot simulation, the less correlated its consecutive steps are, so $\Delta_{\text{spawn}}$ can actually be very low. Each cold simulation runs for $M_\text{init}$ initial steps, that allow the system to cool down, and $M_\text{prod}$ production steps at the target room temperature.

Similar to the previous accelerated methodologies, only a fraction of the explored states can actually be used to perform statistics. In the case of simulated annealing, it corresponded to the cold regions of the simulation; for parallel tempering, only the coldest replica is useful to obtain statistics at that temperature; for the current methodology, the relevant steps are the production of the cold simulation. The main advantage of the shooting star resides in the efficient exploration of the configuration space, rooted in the hot simulation that is independent from the cold ones. Conversely, it lacks the physical meaning of simulated annealing -- which is the numerical counterpart to the annealing process used in metallurgy -- or the time-reversibility of parallel tempering and bare canonical MC.

In terms of parameters, the shooting star method requires choosing $T_\text{hot}$ the hot temperature, $T_\text{cold}$ the cold one, $N_\text{cold}$ the total number of cold simulations to launch, the previously mentioned $M_\text{init}$, $M_\text{prod}$ and $\Delta_\text{spawn}$, as well as the number $N_\text{init}$ of initial steps of the hot simulation before launching the first cold simulation. Of all these parameters, $T_\text{cold}$, $N_\text{init}$ and $N_\text{prod} = M_\text{prod}\times N_\text{cold}$ must also be chosen for a single canonical MC simulation and $\Delta_\text{spawn}$ can always be taken around 100 (its value has little effect on overall performance and quality as long as it is not too low nor too high). The extra parameters $T_\text{hot}$ is equivalent to the hottest temperature used in simulated annealing and parallel tempering. Finally, $M_\text{init}$ must be evaluated by an initial run, similar to how the intermediate temperatures used in parallel tempering are obtained or the slope and plateau lengths of simulated annealing are usually chosen. The complexity of the overall setup is thus similar to that of simulated annealing.


\subsubsection{Extraction of sites from densities}

To perform gas adsorption prediction, what is needed is a model of the cationic zeolite. With this perspective, the previous simulations can be used to simply provide their cation configurations with the lowest energy, in order to obtain such a model.

It is interesting however to evaluate the shooting star methodology as a new general meta-algorithm to simulate systems in sharp energy landscapes. In order to do so, we need a comparison point that can assess the validity of the pseudo-simulation obtained by gluing together all the production steps of the cold simulations. Such a comparison point is the experimental cation localization that can be obtained by X-ray diffraction on zeolite samples with known topology and \SiAl ratio.

The shooting star (or other) simulation method yields a sequence of cation configurations sampled at room temperature. This sequence can be flattened into a map of the zeolite framework, with one additional point at each position occupied by a cation in one of the steps. Looking at this map allows qualitatively identifying the crystallographic sites as the zones where the density of points is the highest. In order to get quantitative information on the site localization and population, we devise a clustering algorithm that extract the sites from the previous density map.

The first step consists in dividing the space by a regular grid, whose voxels have the same angles as the unit cell but possibly different lengths, taken to be closest to a target value around \qty{0.15}{\angstrom}. To each voxel is then attributed the number of cations encountered within across the recorded simulation steps. This first step thus bins the density onto a regular grid.

In the second step, the bins are sorted by decreasing order of their value. Each voxel is then taken in order: if it is closer than a set distance to a previously recorded site, then the location of the site is updated as the average of its current position and that of the voxel, weighted by the respective density of both; the density of the voxel is then aded to that of the site. Otherwise, if it is far enough from all existing sites, it is added to the (initially empty) list of recorded sites, along with its density. This yields a series of sites and their respective occupancy. To be more efficient, the main loop early stops when the density of the inquired voxels go below a threshold value, taken as the maximum density of all bins divided by 100: as a consequence, the occupancies are corrected by a multiplicative factor so that the sum of the occupancies of all sites correspond to the number of cations. We note that this should not be required in theory, but it is the necessary fix to a double discretization artifact, once inherent to the MC scheme, and one due to our binning.

We observe slightly better results by sorting the bins according the the decreasing order their smoothed counterparts, where smoothing is done by convolving the density map by a small Gaussian, of standard deviation the size of the diagonal of a voxel. Indeed, this erases some small statistical fluctuations that may change the precise order of the voxels.

\subsubsection{Validation}

\section{Energy computation}\label{energy_computation}

All of the previously exposed methods rely on Monte-Carlo steps which may, or may not, be accepted, depending on the difference of energy between the two configurations. By far, the greatest computational cost of any of these methods lies in these energy computations; it is therefore crucial to be able to compute it efficiently.

\subsubsection{The RASPA2 software}

RASPA2 is an open-source software developed by [REF] for classical simulations of molecular systems. Although general purpose, it is mainly used with nanoporous materials and in particular for the study of adsorption and diffusion within. RASPA2 implements Monte-Carlo schemes with the Metropolis-Hastings algorithm to perform canonical simulations, but also grand canonical for adsorption (see \cref{adsorption}), as well as parallel tempering. Furthermore, it includes Gibbs ensemble simulation, flexible guest species and frameworks, and many other functionalities which were not needed here.

RASPA2 is written in C, a low-level programming language which allows reaching optimal performance, but is tedious to program in. It cannot be used on GPU and is single-threaded. In order to develop new simulation strategies in an easier setting, I re-implemented the algorithms used for both canonical and grand-canonical simulation of rigid species in rigid frameworks using the Julia programming language (see \cref{julia}).

The energy computation algorithms detailed herein are those which were implemented in this new code, but most of them follow that implemented in RASPA2. Moreover, RASPA2 was used to validate the new code, by checking that the simulations yielded the correct physical values (energies, adsorption capacities, and such). By contrast, the shooting star methodology presented before does not exist in RASPA2.

\subsection{Force fields}

The energy of a molecular structure results from the interaction of its constituent atoms, which are intrinsically quantum. At the molecular level, a popular method used is the quantum Density Functional Theory (DFT), which includes a variety of particular methods, each presenting its own compromise between precision and performance. Some alternatives include methods derived from molecular orbital theory. The number of energy computations for a single molecular simulation can be of the order of \qty{10000} however, which would be much too costly with such methods.

What is commonly used instead are classical force fields, which approximate quantum interactions as a sum of classical interactions between each pair of atoms. These pairwise interactions are defined by one formula per pair of nature of atoms; in the case of non-bonded atoms, each formula is simply a function of the distance between the two atoms. Zeolites are mostly rigid materials, which means that their deformation due to their vibration modes, or subsequent to the organization of cations or adsorbed gas inside, is negligible for the purpose of the molecular simulation. As a consequence, the interactions between framework atoms can be skipped, the only ones to consider for cation placement are those between the cation and the different atoms of the zeolites, which are not bonded.

The pairwise interaction formula is usually divided between the energy contribution of the charges of the atoms, and a short-range van der Waals term. Designing a force fields thus customarily consists in choosing the atomic charges and the formula for the van der Waals term. Several options have been used in the literature for the latter: a very common option is the Lennard-Jones potential
\[r\mapsto 4\varepsilon\paren{\paren{\frac \sigma r}^{12} - \paren{\frac \sigma r}^6}\]
where $r$ is the distance between atoms. One alternative is the Buckingham potential
\[r\mapsto A\exp\paren{-B\times r} - \frac C{r^6}\]
The potential parameter $\varepsilon$, $\sigma$, $A$, $B$ or $C$ are part of the design of the force field.

\subsection{Short-term interactions}

Since the van der Waals term decays quickly towards zero, it is computationnally useful to set it to exactly zero beyond a cutoff distance. To do so while avoiding the introduction of unphysical forces, one possibility consists in shifting the formula by a constant, so that the function remains continuous at the cutoff. If no force is required, such as in the MC methods, it is possible to leave the the potential unshifted and discontinuous at the cutoff, but a constant tail correction can be added to the total energy to account for the missing interactions. In any case, knowing that the interaction becomes zero after the cutoff allows some computational optimizations, such as using cell lists in order to iterate over the relevant atom pairs only, instead of all atom pairs.

For simplicity of the implementation, the dimensions of the simulated unit cell must be taken so that for any atoms $A$ and $B$, there is at most one periodic image of $B$ which is lower than the cutoff distance from atom $A$. This translates to the constraint that the orthogonal lengths of the unit cell must be as long as at least twice the cutoff. We take this cutoff as \qty{12}{\angstrom}, as is common in the literature [REF] and is the default in RASPA2.

Given this constraint, the total energy of a configuration due to the van der Waals interaction can be computed by summing the contribution of each the pair of atoms which are closer than the cutoff distance. This can done naively with a double loop over all atoms, computing the distance of each pair and rejecting that above the threshold. Here, the distance considered is the periodic distance, \textit{i.e.} the smallest distance between periodic images of the two atoms, respective to the periodicity of the crystal. Computing it is up to 6 times more costly than without periodicity, and can become a computational bottleneck for simple enough force fields.

To avoid unecessary distance computations, a possibility consists in binning the space of the unit cell, and skipping the pairs of atoms that belong to bins further than the cutoff distance. This idea underlies the principle of neighbour list which can be used to obtain the list of relevant pairs of atoms efficiently. We use the CellListMap.jl [10.1016/j.cpc.2022.108452] julia package for this purpose, although we only enable it when the cell is large enough since the naive approach can be more efficient in many cases where the orthogonal lengths of the cell are close to twice the cutoff distance.

\subsection{Ewald summation}

\subsubsection{Energy decomposition}

In opposition to the van der Waals term, charge interactions do not have a cutoff, because Coulomb's law does not decay fast enough towards zero. The interaction between atoms $A$ and $B$, of respective charge $q_A$ and $q_B$, is:
\[E^\text{Coulomb}_{A,B} = \frac{q_A q_B}{4\pi\varepsilon_0\times \norm{\boldsymbol r_B - \boldsymbol r_A}} = \frac{q_n q_m}{4\pi\varepsilon_0\times \norm{\boldsymbol r_m - \boldsymbol r_n + \boldsymbol l}}\]
where $n$ and $m$ are the unique atom numbers in a reference unit cell of respectively $A$ and $B$, and $\boldsymbol l$ is the lattice vector between the origin of the unit cell of $A$ and that of $B$.
Therefore the total contribution of charge interactions in a crystal with $N$ atoms per unit cell is:
\[E^\text{Coulomb} = \frac12\sum_{A\neq B}E^\text{Coulomb}_{A,B}
                   = \frac1{8\pi\varepsilon_0}\sum_{\boldsymbol l}\underset{n\neq m\text{ if }\boldsymbol l = 0}{\sum_{n=1}^N\sum_{m=1}^N} \frac{q_n q_m}{\norm{\boldsymbol r_n - \boldsymbol r_m + \boldsymbol l}}\]
where $\boldsymbol l$ iterates over the lattice vectors.

The semi-convergence of the sum over $\boldsymbol l$ makes it impossible to compute directly. Hence, several methods have been developped to obtain the result such as particle mesh Ewald (PME) and particle-particle-particle-mesh (P$^3$M). We focus on the initial Ewald summation technique underlying them, which is used in RASPA2 and which we also implemented.

Since the crystal is a periodic system, any function of the system that depends on a position in space can be decomposed into a simple sum by Fourier transform. This is in particular true of the electric potential, hence the problematic sum above could be computed in Fourier space. However, the charges are located on the atoms, and are thus discrete, which causes singularities that prevent the computation. The idea behind Ewald summation consists in fictitiously smoothing the point charges into Gaussians: these smooth charges yield a potential computable in Fourier space, while the potential resulting from the real point charge minus their Gaussian counterpart is computed in real space. Electric potential is additive, so the total electric potential $\Phi(\boldsymbol r)$ is then obtained by adding the real space term $\Phi^\text{direct}(\boldsymbol r)$ and the Fourier term $\Phi^\text{reciprocal}(\boldsymbol r)$. Finally, the resulting energy is simply the action of the point charges on the potential:
\[E^\text{Coulomb} = \frac12\sum_{n=1}^N q_n\paren{\Phi^\text{direct}(\boldsymbol r_n) + \Phi^\text{reciprocal}(\boldsymbol r_n)} - E^{\text{self}}\]
$E^{\text{self}}$ designates a spurious self-interaction energy term which must be substracted.

\subsubsection{Direct term}

To each atom $A$ of the crystal is associated a Gaussian charge density
\[\boldsymbol r\mapsto q_A\paren{\frac\alpha{\sqrt\pi}}^3\exp\paren{-\alpha^2\norm{\boldsymbol r_A - \boldsymbol r}^2}\label{gaussian_charge}\]
Thus, the direct term is the potential resulting from the point charge minus this Gaussian. This can be obtained by solving Poisson's law:
\[-\nabla\Phi(\boldsymbol r) = 4\pi\rho(\boldsymbol r)\label{Poisson}\]
which yields, after some simplification steps not detailed here:
\[\Phi^\text{direct}_A(r) = q_A\frac{\text{erfc}(\alpha r)}r\]
where $r$ is the distance to atom $A$ and $\text{erfc}$ is the complementary error function $\text{erfc} = 1 - \text{erf}$, with $\text{erf}:x\mapsto\frac2{\sqrt\pi}\int_0^xe^{-t^2}\text dt$. Since $\text{erfc}$ quickly decays towards $0$, the total direct potential at a given point can be computed by only considering the contribution of the closest charges around, so
\[\Phi^\text{direct}(\boldsymbol r) \approx \sum_{n=1}^N \frac{q_n}{\pnorm{\boldsymbol r - \boldsymbol r_n}}\paren{\text{erfc}\paren{\alpha \pnorm{\boldsymbol r - \boldsymbol r_n}}}\]
where $\pnorm{\boldsymbol x}$ designates the distance to the origin of the closest periodic image of $\boldsymbol x$.

\subsubsection{Reciprocal term}

For the reciprocal term, we start by writing the total charge density coming from the Gaussians given in \cref{gaussian_charge}:
\[\rho^\text{reciprocal}(\boldsymbol r) = \sum_{\boldsymbol l}\sum_{n=1}^N \frac{q_n}{4\pi\varepsilon_0}\paren{\frac\alpha{\sqrt\pi}}^3\exp\paren{-\alpha^2\norm{\boldsymbol r_n + \boldsymbol l - \boldsymbol r}^2}\]
Its Fourier decomposition over the periodic unit cell of volume $V$ is:
\[\begin{split}
\hat\rho^\text{reciprocal}(\boldsymbol k) &= \frac1V\int_V e^{-i\boldsymbol k\cdot\boldsymbol r} \rho^\text{reciprocal}(\boldsymbol r)\text d\boldsymbol r
\\&= \frac1V\int_\Omega e^{-i\boldsymbol k\cdot\boldsymbol r} \sum_{n=1}^N \frac{q_n}{4\pi\varepsilon_0} \paren{\frac\alpha{\sqrt\pi}}^3\exp\paren{-\alpha^2\norm{\boldsymbol r_n + \boldsymbol r}^2} \text d\boldsymbol r
\\&= \frac{2\pi\alpha^3}{V\pi^{3/2}} \sum_{n=1}^N \frac{q_n}{4\pi\varepsilon_0} e^{-i\boldsymbol k\cdot\boldsymbol r_n} \int_0^\infty \norm{\boldsymbol{r}'}^2\exp\paren{-\alpha^2 \norm{\boldsymbol{r}'}^2}\int_0^\pi e^{-i\boldsymbol k\cdot\boldsymbol{r}'} \sin(\theta) \text d \theta \text d \boldsymbol{r}'
\\&= \frac1{4\pi\varepsilon_0V}\exp\paren{\frac{-k^2}{4\alpha^2}}\sum_{n=1}^N q_n e^{-i\boldsymbol k\cdot\boldsymbol r_n}\end{split}\]
after several simplification steps not detailed here. Using Poisson's law (\cref{Poisson}), the electric potential due to the Gaussians can then finally be expressed as:
\[\Phi^\text{reciprocal}(\boldsymbol r) = \frac{1}{\varepsilon_0V}\sum_{\boldsymbol k\neq \boldsymbol 0}\sum_{n=1}^N \frac{q_n}{k^2} e^{i\boldsymbol k\cdot\paren{\boldsymbol r - \boldsymbol r_n}}\exp\paren{\frac{-k^2}{4\alpha^2}}\label{eq:reciprocal}\]

The term $\kappa_{\boldsymbol{k}} = \frac1{k^2}\exp\paren{-k^2/(4\alpha^2)}$ decays fast, so the sum over $\boldsymbol{k}\neq\boldsymbol{0}$ is actually computed as a sum over a finite number of values of $\boldsymbol{k}$. These values are chosen so that for any $\boldsymbol{k}$ not retained, $\kappa_{\boldsymbol{k}}$ is below the target precision of the computation.

\subsubsection{Self-interaction term}

The last remaining term is the self-interaction, which must be removed. Its existence comes from the way the reciprocal term is computed: $\Phi^\text{reciprocal}(\boldsymbol r)$ includes the contribution of all charges on point $\boldsymbol r$, but there should not be any contribution of atom $A$ at position $\boldsymbol r_A$.

Moreover, in the case of rigid polyatomic molecules, like the small gases we will discuss in \cref{adsorption}, there should not be any contribution of atom $A$ at the positions $\boldsymbol r_B$ of other atoms $B$ part of the same molecule.

Each atom $1\le n\le N$ thus contributes a spurious potential term:
\[\Phi^\text{self}_n = \frac{2\alpha q_n}{\sqrt\pi} + \frac12\sum_{\substack{m\\m\smile n,\ m\neq n}}\frac{q_m\text{erf}\paren{\pnorm{\boldsymbol r_n - \boldsymbol r_m}}}{4\pi\varepsilon_0\pnorm{\boldsymbol r_n - \boldsymbol r_m}}\]
where $m\smile n$ is true when both atoms $m$ and $n$ belong to the same molecule.

\subsubsection{Total charge energy}

Combining the last three terms, we obtain the overall Coulomb energy:
\[\begin{split}
E^\text{Coulomb} &= \sum_{\boldsymbol l} \sum_{n=1}^N\sum_{\substack{m=1\\m\not\smile n}}^n \frac{q_n q_m}{8\pi\varepsilon_0}\frac{\text{erfc}\paren{\alpha\norm{\boldsymbol r_n - \boldsymbol r_m + \boldsymbol l}}}{\norm{\boldsymbol r_n - \boldsymbol r_m + \boldsymbol l}}
\\&+ \frac1{2\varepsilon_0V} \sum_{\boldsymbol{k}\neq\boldsymbol{0}}\sum_{n=1}^N\sum_{m=1}^N \frac{q_n q_m}{k^2}e^{i\boldsymbol k\cdot\paren{\boldsymbol r_m - \boldsymbol r_n}}\exp\paren{\frac{-k^2}{4\alpha^2}}
\\&- \sum_{n=1}^N\frac{2\alpha q_n}{\sqrt\pi} - \frac12\sum_{n=1}^N\sum_{\substack{m=1\\m\smile n,\ m\neq n}}^N \frac{q_n q_m}{4\pi\varepsilon_0}\frac{\text{erf}\paren{\pnorm{\boldsymbol r_n - \boldsymbol r_m}}}{\pnorm{\boldsymbol r_n - \boldsymbol r_m}}
\end{split}\]

\subsection{Precomputation}

Different algorithms that solve a particular problem generally differ in the specific space-time tradeoff they choose. Obtaining the energy of a configuration presents the same possibility: while entirely computing the energy from scratch requires a set amount of computation, it is possible to make subsequent computations faster at the cost of a greater memory footprint of the algorithm, by storing some intermediate results which can be reused afterwards.

\subsubsection{Energy grid}

\label{energygrid}

In the case of simulations involving a rigid framework, the most obvious precomputation that can be done is that of the short-term interactions of the guest species with the framework atoms. Indeed, such interactions only depend on the nature and the position of the guest atom, so it is possible to store them on an energy grid.

More precisely, fore each possible guest atom, the unit cell of the framework is divided into a regular grid, with a set spacing between consecutive points. We use \qty{0.15}{\angstrom}, which is fine enough to be accurate but not too fine to avoid using too much memory. For each grid point, the sum of the interactions of all framework atoms with a guest atom in that position is stored at that point. The grid is then written to disk.

During the simulation, in order to compute the short-term interactions between the framework atoms and a guest atom at a given position, the value is interpolated from the surrounding grid points. Using a simple linear interpolation of the values does not yield very satisfactory results however, since derivative discontinuity would push that atoms towards the grid points, which would result in simulation artifacts. To prevent this, RASPA2 stores not only the value of the energy, but also the three first derivatives, three values of the second derivatives and one of the third, following a scheme by [REF]. Moveover, the grid is forced to be orthorombic: this means that it may not be aligned with the unit cell of the framework, but it does not matter as long as each point in the unit cell can be surrounded by recorded grid points. I reimplemented the same grid algorithm, which ensures a smooth interpolation everywhere in space.

\subsubsection{Ewald precomputation}

Short-term interactions that can be stored in grids include the short-term direct part of the Ewald summation. The reciprocal term cannot however be simply stored as such.

Yet, it is still possible to precompute a large part of the reciprocal interaction which is due to the framework. Looking back at \cref{eq:reciprocal}, the list of relevant $\boldsymbol{k}$, associated to their factor $\exp\paren{-k^2/\paren{4\alpha^2}}/k^2$, is computed once and for all. For each atom $n$, the factors $\exp\paren{\boldsymbol{k}\cdot\boldsymbol{r}_n}$ are also computed once. Hence, \cref{eq:reciprocal} can be rewritten as
\[\begin{split}\Phi^\text{reciprocal}(\boldsymbol r) &= \frac{1}{\varepsilon_0V}\sum_{\boldsymbol k\neq \boldsymbol 0}e^{i\boldsymbol{k}\cdot\boldsymbol{r}}\underbrace{\frac1{k^2}\exp\paren{\frac{-k^2}{4\alpha^2}}\left(\sum_{n\text{ framework}} q_n e^{-i\boldsymbol k\cdot\boldsymbol r_n}\right.}_\text{precomputed part}\left. + \sum_{n\text{ guest}} q_n e^{-i\boldsymbol k\cdot\boldsymbol r_n}\right)
\\&= \frac1{\varepsilon_0V}\sum_{\boldsymbol k\neq \boldsymbol 0} \kappa_{\boldsymbol k} F_{\boldsymbol k} e^{i\boldsymbol{k}\cdot\boldsymbol{r}} \ +\  \frac1{\varepsilon_0V}\sum_{\boldsymbol k\neq \boldsymbol 0} \kappa_{\boldsymbol k} e^{i\boldsymbol{k}\cdot\boldsymbol{r}} \sum_{n\text{ guest}} q_n e^{-i\boldsymbol k\cdot\boldsymbol r_n}
\label{eq:reciprocal_decomposed}\end{split}\]
where $\kappa_{\boldsymbol k} = \frac1{k^2}\exp\paren{-k^2/(4\alpha^2)}$ and $F_{\boldsymbol k} = \sum\limits_{n\text{ framework}} q_n e^{-i\boldsymbol k\cdot\boldsymbol r_n}$ are precomputed terms.

Finally, the entire self-interaction term can be computed once for all, since it does not depend on the configuration. This is only the case here because the simulated moleculses are rigid bodies; for deformable structures, the self-interaction term depends on the actual conformation of the guests, which may depend on the state.

\subsubsection{Blocking pockets}

Some MC trial moves attempt to displace an atom to a location that would lead to unphysically high energies -- typically, too close to a framework atom. Such positions can be determined once and for all, and the relevant MC moves automatically refused without the need for any energy computation.

To do so, the simplest strategy consists in making a boolean grid, aligned with the energy grids used for short-term interactions, which stores a 1 when the voxel is blocked or 0 if it is allowed. The first step of any MC trial move then consists in checking whether each atom is in an allowed voxel, or refusing the move otherwise. In practise, the simplest implementation consists in making one such boolean grid per atom kind (since the energy threshold depends on the atom), and for each atom, checking the closest grid point of its kind.

In addition to its use as computational optimization, such boolean grids can also be used to mark some parts of the framework as inaccessible, irrespective of the corresponding energy. This is useful when small window size prevents a species -- for instance a gas molecule -- from entering a pore -- for instance the sodalite cages in LTA zeolites [10.1021/ja953856q]. Indeed, without explicitly blocking the pocket, an MC move could make a species appear in the pore, whereas it should be kinetically impossible to enter. This strategy will thus be used when studying the adsorption of gases in zeolites (see \cref{adsorption}), but for the small cations under study here, there is no need to additionally block any part of the frameworks.

RASPA2 only implements blocking for the latter case -- \textit{i.e.} explicit pocket removal. It does not use a boolean grid: instead, the blocked space is described as a combination of blocking spheres. For each trial move, the distance between the atoms of the moved guest and the center of each sphere is computed: if one is below its radius, the move is rejected. This approach requires less precomputation and thus less memory than storing the boolean grids, but its cost is much greater, and increases with the number of blocking spheres, preventing it from being used as an optimization like before. It is thus less efficient than the approach I implemented.

\subsubsection{Optimizations for computing the difference of energies}

A simulation that follows the Metropolis-Hastings algorithm walks across configurations, each pair of contiguous states being separated by a single MC move. In this context, computing the energy of each trial configuration to compare it to the previous one is wasteful: the only part of the energy impacted by the MC move is that which stems from the moved species. Instead of computing the energy of the trial configuration, it is thus better to directly compute the energy difference due to the move.

For the short-term interactions, this is straightforward: the energy difference is simply the sum of the interactions of the species at the new position minus that at its previous position. If there are $N$ species, moving one thus costs $O(N)$ computations for these terms, instead of $O(N^2)$ required to compute this energy the first time. The direct part of the Ewald summation follows the same principle.

For the reciprocal part, \cref{eq:reciprocal_decomposed} can be revisited by removing the first constant term, and singling out the atoms $n$ for the moved species:
\[\Delta\Phi^\text{reciprocal}(\boldsymbol{r}) = \frac1{\varepsilon_0V}\sum_{\boldsymbol{k}\neq\boldsymbol{0}} \kappa_{\boldsymbol k}e^{i\boldsymbol k\cdot\boldsymbol{r}} \sum_{n\text{ moved}}q_n\paren{e^{-i\boldsymbol k\cdot\boldsymbol{r}'_n} - e^{-i\boldsymbol k\cdot\boldsymbol r_n}}\]
where $\boldsymbol{r}'$ is the position after the move and $\boldsymbol{r}$ before.

In order to allow computing this efficiently, each term $e^{-i\boldsymbol k\cdot\boldsymbol r_n}$ is thus stored in memory (instead of recomputing it each time). The new values $e^{-i\boldsymbol k\cdot\boldsymbol{r}'_n}$ computed for the trial move are also temporarily kept in memory, so they can be used to replace the previous ones if the trial move is accepted. RASPA2 does not implement this optimization, and simply recomputes the $e^{-i\boldsymbol k\cdot\boldsymbol r_n}$ terms each time, which is slower but requires less memory.

% \begin{figure}[ht]
%   \centering
%   \begin{subfigure}[b]{0.45\textwidth}
%     \centering
%     \includegraphics[height=0.7\textwidth]{figures/something.pdf}
%     \caption{Experimental}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.45\textwidth}
%     \centering
%     \includegraphics[height=0.7\textwidth]{figures/else.pdf}
%     \caption{Theoretical calculation}
%   \end{subfigure}
%   \caption{Illustration of something (a) else (b). See also\textsuperscript{1} by Ref.~\cite{foo}. }\label{something_else}
% \end{figure}
% \footnotetext[1]{Available on Github at \url{https://github.com/foo}}


\section{Possible alternatives}

\label{metadynamics}

Molecular dynamics (MD) could also be used to place cations in zeolites. Generally speaking, the principle of MD consists in running a simulation where the particles follow Newton's laws of motion, with forces based on force fields like for MC schemes. The simulation is divided in time steps, between which the forces are computed on each particle to derive their position at the next time step. Hence, the trajectories of the particles in MD follow a physical path.

Temperature can be included in different ways in MD, all of which use an element of randomness that eventually impacts the velocities of particles, in order to ensure that the average values extracted from the simulation correspond to those which would be obtained at that temperature. This means that the precedent discussion on the inaccessibility of high-energy regions to the system at room temperature still applies in MD.\@ A simple MD simulation is thus doomed to only explore local energy minima, failing to reach ergodicity like with the simple canonical MC scheme.

To circumvent this issue, it is necessary to bias the simulation in order to force the system to explore regions of high energy. One such strategy consists in doing metadynamics [REF], which is a variation of MD in which the potential energy landscapes is modified during the simulation. The effective free energy of a point in configuration space is computed as the sum of the real free energy of that point without bias, added to the sum of some Gaussian functions centred on previously explored points. Every few steps, another Gaussian function centred on the current configuration point is added to the bias, so that the effective free energy of explored regions increases through the simulation, which allows the system to eventually escape local minima and explore other regions.

A Gaussian is a function of the form $f:\boldsymbol x\mapsto Ae^{-\paren{\boldsymbol x - \boldsymbol\mu}^\top\Sigma\paren{\boldsymbol x - \boldsymbol\mu}}$. In practise, the variable $\boldsymbol x$ of the Gaussians used in metadynamics are not directly the $3N$ coordinates of the $N$ particles, but a small-dimensional vector whose coordinates are called ``collective variables''. These collective variables are themselves function of the $3N$ initial coordinates. The parameter $A$ and $\Sigma$ of the Gaussians being usually fixed, each Gaussian is stored by its centre $\boldsymbol\mu$, whose coordinates are thus the collective variables of the current configuration point. Therefore, compared to regular MD, running a metadynamics simulation incurs the additional cost of computing the collective variables $\boldsymbol x$ of each visited configuration point, storing the Gaussians' centres, and computing their value at each step.

For cation placement the main issue is to find a small set of relevant collective variables, since the cost of metadynamics grows with their number. We did not explore this venue because we expected it to be similar in difficulty to the MC alternatives, with no clear reason why it should be more efficient. MD in general is also known to converge more slowly than MC, because large configuration change made possible by MC steps are prohibited by the physics-driven approach of MD, and the same argument could be made of metadynamics compared to other accelerated MC schemes. Exploring metadynamics or its variants could nonetheless be of interest in the search for more alternative, and potentially more efficient, algorithms.

\OnlyInSubfile{\printglobalbibliography}

\end{document}
